Design for the C code
=====================

Let's do recursive descent first.  It's simple and we can try to limit
the stack manually (currently CPython only allows about 100 nested
parentheses so that's okay).

Parser structure
----------------

Also needs to point to a PyArena, used for allocating AST nodes and
other things.  And maybe some flag indicating there's an allocation
error and a convention to bail if there is one.

Possibly return Py_None for "no match" rather than NULL?  That will
allow NULL to mean "error" (other than syntax error or EOF).

- tok: Pointer to tokenizer, CPython's struct tok_state
- input: Pointer to input bytes (char *), same as tok->input (owned by tok).
         (Not used though.  And tokenizing from file won't have it.)
- tokens: Pointer to array of Token structs
- mark: index into array of Tokens
- fill: number of valid entries in array of Tokens
- size: total number of entries in array of Tokens

Token structure
---------------

These are in an array linked from Parser.  (Or linked list???)

- type: int, token type (needs only 8 bits)
- value: bytes object [or maybe just two indices into parser->input?)
- line, col, endline, endcol: int
- memo: Pointer to linked list Memo

Memo structure
--------------

Linked list, optimized for quickly finding a given type.  (Or array???)

- type: int, either a token or a rule (rules start at 256)
- node: NULL or pointer to AST node OR pointer to token object (TODO)
- mark: if node != NULL, index into Parser's array of tokens
- next: NULL or pointer to next Memo structure

C function for a rule
---------------------

Similar to the Python functions, but memoziation is done here.

#define type_expr  321  // Some constant representing the rule 'expr'

static AST*
rule_expr(Parser *p)
{
    AST *res = NULL;
    int mark = p->mark;
    if (res = is_memoized(p, type_expr))
        return res;
    // Alternatives start here
    if ((a = rule_a(p)) && (b = rule_b(p)) && (c = rule_c(p))) {
        // On success
        res = <make new AST node from (a, b, c)>
        insert_memo(p, mark, type_expr, res);
        return res;
    }
    p->mark = mark;
    // More alternatives...
    ...
    // At the end
    // Memoize negative result too!
    insert_memo(p, mark, type_expr, NULL);
    return NULL;
}

// Here, mark is the start of the node, while p->mark is the end.
// If node==NULL, they should be the same.
static void
insert_memo(Parser *p, int mark, int type, AST *node)
{
    // Simplest: insert in front
    Memo *m = malloc(sizeof(Memo));
    if (m == NULL)
        panic();  // TODO: How to handle malloc failures
    m->type = type;
    m->node = node;
    m->mark = p->mark;
    m->next = p->tokens[mark].memo;
    p->tokens[mark].memo = m;
}

static AST *
is_memoized(Parser *p, int type)
{
    // Possible optimization: sort Memos by type.
    Token *t = &p->tokens[p->mark];
    Memo *m;
    for (m = t->memo; m != NULL; m = m->next) {
        if (m->type == type) {
            if (m->node = NULL)
                return NULL;
            p->mark = m->mark;
            return m->node;
        }
    }
    return NULL;
}

OLD NOTES
=========

Design for the VM

opcodes:

expect_token(token_id)
call_rull(rule_id)
start_optional(forward_dest)
end_optional(code_frag_id)
start_loop0(forward_dest)
end_loop0(code_frag_id)
start_loop1(forward_dest)
end_loop1(code_frag_id)
start_alt(dest)
end_alt()

state in stack frame:

link to previous stack frame
link to opcode array
program counter (index into opcode array)
stack of values returned by rules and tokens
stack of end destinations and their types
  i.e. active optionals and loops
stack of marks (indexes into token array)

dynamic global state:

array of input tokens (lazily grows as needed)
input position (index into array of input tokens)
token cache
  indexed by (input position, token_id)
  gives either None or (token, new input position)
symbol cache
  indexed by (input position, rule_id)
  gives either None or (tree, new input position)

static global state:

opcode arrays for all rule_ids
table of code fragments to be used for building the tree

how does the engine work:

tokenizer is a black box
all global state is input
rule_id for start symbol is given
create first stack frame (all stacks empty)
use opcode array from start rule_id
put pc at 0
loop:
  decode next opcode, move pc
  execute opcode
  if it's an uncached call, create a new stack frame
when falling of the end or upon completion of a top-level alternative:
  should have one node in hand
  if there's a back link, resume previous frame, back to (loop:) above
  else that's the tree for the entire parse
when failing and there's no back link:
  report a syntax error at the furthest point the tokenizer made it


----------
start over
----------

Dynamic state should not be used to keep track of static properties of
the program (e.g. what to do if a rule call fails).  It should be used
only for:

- return address from a rule call
- values collected so far ($1, $2, ...)
- return value of last call ($$)

The rest can be expressed in the opcodes directly, e.g.

expr: term '+' term { $$ = $1 + $3 } | term '-' term { $$ = $1 - $3 } | term { $$ = $1 }

Let's say opcodes have two extra fields, next=N, fail=N, giving labels
of where to go on success or failure.  Also another extra field where
to store the value on success.

# Rule expr

# term '+' term { $$ = $1 + $3 }
L0:  call term; store=$1; next=L1; fail=L5
L1:  expect '+'; store=$2; next=L2; fail=L5  # No store!
L2:  call term; store=$3; next=L3; fail=L5
L3:  exec "$$ = $1 + $3"; next=L4
L4:  return $$

# term '-' term { $$ = $1 - $3 }
L5:  call term; store=$1; next=L6; fail=L10
L6:  expect '-'; store=$2; next=L7; fail=L10
L7:  call term; store=$3; next=L8; fail=L10
L8:  exec "$$ = $1 - $3"; next=L9
L9:  return $$

# term { $$ = $1 }
L10: call term; store=$1; next=L11; fail=L13
L11: exec "$$ = $1"; next=L12
L12: return $$

13: fail

Hm, okay, so next is always the next instruction, so we don't need
that, unless the instructions are stored in a dict.

Variables per stack frame:
$$ (return from exec block)
$1, $2, $3, ... (results from call and expect)

Then we need a stack of frames, so each rule in progress has its own
variables.  In addition to the above $ variables, the stack frame
needs a program counter so when a frame is popped we know where to
continue.

Upon return from a (rule) call we take the return value (always $$?)
from the called frame and store it in the calling frame at the spot
indicated by store=$VAR, then move to the next instruction.  We
indicate failure by returning NULL (an old tradition).

So how do we generate code for an optional field?

term: ['-'] NAME { $$ = -$2 if $1 else $2 }

L1: expect '-'; store=$1; next=L2; fail=L2
L2: expect NAME; store=$1; next=L3
L3: exec "$$ = -$2 if $1 else $2"; next=L4
L4: return $$

What about a longer optional field?

factor: atom ['*' atom] { $$ = $1 * $3 if $2 else $1 }

L1: call atom; store=$1; next=L2; fail=L6
L2: expect '*'; store=$2; next=L3; fail=L4
L3: call atom; store=$3; next=L4; fail=L7
L4: exec "$$ = $1 * $3 if $2 else $1"; next=L5
L5: return $$
L6: fail
L7: clear $2; next=L4

Here the weird new thing is the clear instruction, needed to erase the
traces of the '*' already stored in $2 when we don't find an atom
following the '+'.

??? A different approach here would be to store the result of ['+'
atom] in a combining node (like a tuple).  But then the executable
code needs to be aware of that. ???

What about an optional field containing alternatives?

factor: atom ['*' atom | '/' atom] { $$ = $1 * $3 if $2 else $1 * $5 if $4 else $1 }

-------------------------

...New Python code generator, using new Node concept...

- For each rule generate a function named after that rule, e.g.

  # term: factor '*' factor {action1} | factor {action2}
  @memoize
  def term(self):
      if self.factor() and self.expect('*') and self.factor():
          ...
  @memoize
  def factor(self):
      ...


- For each complex item also generate a function, e.g. in this case

  # term: factor ('*' | '/') factor {action1} | factor {action2}
  @memoize
  def term(self):
      if self.factor() and self.tmp_1() and self.factor():
          ...
  @memoize
  def factor(self):
      ...
  @memoize
  def tmp_1(self):
      return self.expect('*') or self.expect('/')

- For [x] or x? generate a function that returns x or None (but the
  latter is not failure).  If x is simple, this is just self.x().
  If x is more complex, generate a function tmp_N for it.  The caller
  has something like this:

  # expr: left [op] right
  @memoize
  def foo(self):
      if ((l := self.left()) and
          ((op := self.op()) or True) and
          (r := self.right())):
        return [left, op, right]

- For x* and x+ generate a function that returns a list of nodes; for
  x+, the caller treats an empty list as error.  Either way the code
  is like this:

  # caller: left x* right
  @memoize
  def caller(self):
      if (l := self.left()) and ((xs := self.tmp_x()) or True) and (r := self.right()):
          return [l, xs, r]

  @memoize
  def tmp_x(self):
      xs = []
      while (x := self.x()):
          xs.append(x)
      return xs

---

Running into some problems...

My current approach omits trivial parse tree nodes, e.g. if a rule has
only one alternative it doesn't return an Alts() node, and if an
alternative has only one item, it doesn't return an Alt() node.  But
this makes code generation a bit tricky.  Maybe I should revert this
design decision.  We'd get

  Rule(name: str, rhs: Alts)
  Alts(alts: List[Alt])
  Alt(items: List[Union[NamedItem, Item]], action: str)
  NamedItem(name: str, item: Item)
  Item(x: Union[Plain, Opt, Repeat0, Repeat1])
  Plain(x: Atom)
  Opt(aa: Atom)
  Repeat(aa: Atom)
  Group(aa: Alts)

  Atom = Union[Leaf, Group]
  Leaf has subtypes NamedNode, StringNode
  Repeat has subtypes Repeat0, Repeat1

Or maybe:
  Alts = List[Alt]
  Plain = Atom

So we get:

  Rule(name: str, rhs: List[Alt])
  Alt(items: List[NamedItem]], action: str)
  NamedItem(name: Optional[str], item: Item)
  Plain(a: Atom)
  Opt(a: Atom)
  Repeat(a: Atom)
  Group(aa: List[Alt])

  Item = Union[Plain, Opt, Repeat]
  Atom = Union[Leaf, Group]

  NamedNode <: Leaf
  StringNode <: Leaf

  Repeat0 <: Repeat
  Repeat1 <: Repeat
